{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4213460,"sourceType":"datasetVersion","datasetId":2483929}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndata_csv = pd.read_csv('/kaggle/input/fsc22-dataset/Metadata-20220916T202011Z-001/Metadata/Metadata V1.0 FSC22.csv')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:45:04.534655Z","iopub.execute_input":"2026-01-31T15:45:04.535099Z","iopub.status.idle":"2026-01-31T15:45:06.373635Z","shell.execute_reply.started":"2026-01-31T15:45:04.535062Z","shell.execute_reply":"2026-01-31T15:45:06.372517Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_csv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:45:13.604060Z","iopub.execute_input":"2026-01-31T15:45:13.604386Z","iopub.status.idle":"2026-01-31T15:45:13.641209Z","shell.execute_reply.started":"2026-01-31T15:45:13.604356Z","shell.execute_reply":"2026-01-31T15:45:13.640165Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                       Source File Name Dataset File Name  \\\n0                                          17548__A.wav       1_10101.wav   \n1                                           17548_B.wav       1_10102.wav   \n2                                           17548_C.wav       1_10103.wav   \n3                                           17548_D.wav       1_10104.wav   \n4                                           17548_E.wav       1_10105.wav   \n...                                                 ...               ...   \n2020                   164882__timsc__squirrel-call.wav      27_12771.wav   \n2021  162648__cognito-perceptu__park-bench-atmospher...      27_12772.wav   \n2022         122260__echobones__angry-squirrel-long.wav      27_12773.wav   \n2023  82828__noisecollector__angrysquirrel-creepingt...      27_12774.wav   \n2024  82829__noisecollector__angrysquirrel-flyingair...      27_12775.wav   \n\n      Class ID Class Name  \n0            1       Fire  \n1            1       Fire  \n2            1       Fire  \n3            1       Fire  \n4            1       Fire  \n...        ...        ...  \n2020        27   Squirrel  \n2021        27   Squirrel  \n2022        27   Squirrel  \n2023        27   Squirrel  \n2024        27   Squirrel  \n\n[2025 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source File Name</th>\n      <th>Dataset File Name</th>\n      <th>Class ID</th>\n      <th>Class Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17548__A.wav</td>\n      <td>1_10101.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17548_B.wav</td>\n      <td>1_10102.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17548_C.wav</td>\n      <td>1_10103.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17548_D.wav</td>\n      <td>1_10104.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17548_E.wav</td>\n      <td>1_10105.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>164882__timsc__squirrel-call.wav</td>\n      <td>27_12771.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2021</th>\n      <td>162648__cognito-perceptu__park-bench-atmospher...</td>\n      <td>27_12772.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2022</th>\n      <td>122260__echobones__angry-squirrel-long.wav</td>\n      <td>27_12773.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2023</th>\n      <td>82828__noisecollector__angrysquirrel-creepingt...</td>\n      <td>27_12774.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2024</th>\n      <td>82829__noisecollector__angrysquirrel-flyingair...</td>\n      <td>27_12775.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n  </tbody>\n</table>\n<p>2025 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"We have 2025 data sets as our audio data sets.\n\nto Augment the data set and widen it we pitch 2 steps up and down in each audio file","metadata":{}},{"cell_type":"code","source":"import librosa\nimport soundfile as sf\nfrom tqdm import tqdm\nimport os\n\ninput_dir = \"/kaggle/input/fsc22-dataset/Audio Wise V1.0-20220916T202003Z-001/Audio Wise V1.0\"\n\noutput_dir = \"/kaggle/working/FSC22_augmented\"\nos.makedirs(output_dir, exist_ok = True)\n\n\nPITCH_STEPS = [2,-2]\n\nfor file in tqdm(os.listdir(input_dir)):\n    if file.endswith(\".wav\"):\n        file_path = os.path.join(input_dir, file)\n\n        y, sr = librosa.load(file_path, sr=None) #loading the audio\n\n        sf.write(os.path.join(output_dir, file),y,sr)\n\n        for step in PITCH_STEPS:\n            y_shifted = librosa.effects.pitch_shift(y,sr= sr, n_steps=step)\n            base, ext = os.path.splitext(file)\n            new_filename=f\"{base}_pitch{step}{ext}\"\n            sf.write(os.path.join(output_dir, new_filename), y_shifted, sr)\n\nprint(\"Augmentation Completed!\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:45:17.846593Z","iopub.execute_input":"2026-01-31T15:45:17.847168Z","iopub.status.idle":"2026-01-31T15:55:35.098658Z","shell.execute_reply.started":"2026-01-31T15:45:17.847131Z","shell.execute_reply":"2026-01-31T15:55:35.097571Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2025/2025 [10:17<00:00,  3.28it/s]","output_type":"stream"},{"name":"stdout","text":"Augmentation Completed!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"filename_to_label= {}\n\nfor i, row in data_csv.iterrows():\n    filename = row[\"Dataset File Name\"]\n    class_id = row[\"Class ID\"]\n    filename_to_label[filename] = class_id\n\ndef get_orginal_filename(filename):\n    base, ext = os.path.splitext(filename)\n    if \"_pitch\" in base:\n        base = base.split(\"_pitch\")[0]\n    return base + ext\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:12:47.495611Z","iopub.execute_input":"2026-01-31T16:12:47.498047Z","iopub.status.idle":"2026-01-31T16:12:47.616060Z","shell.execute_reply.started":"2026-01-31T16:12:47.497997Z","shell.execute_reply":"2026-01-31T16:12:47.615020Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Since we have augmented the data set now we are trying to do feature extraction.\n\nfor ausio signal processing, we use MFCC and melspectrogram methods using librosa library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nauto_dir = \"/kaggle/working/FSC22_augmented\"\n\n#Feature Extraction Parameters\n\nSR = 22050 #sampling rate\nN_FFT = 2048  #number of samples per FFT window\nHOP_LENGTH = 512 #\nN_MELS = 128 #number of mel frequency bands. 128 is ide\nN_MFCC = 13 #number of MFCC coefficients\n\ndef extract_mel_spectrogram(file_path):\n    y, sr = librosa.load(file_path, sr=SR) # Y is the 1D waveform array\n    mel_spec = librosa.feature.melspectrogram( y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n    mel_specs_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n    return mel_specs_db\n\ndef extract_mfcc(file_path):\n    y, sr = librosa.load(file_path, sr=SR)\n    mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=N_MFCC,n_fft=N_FFT,hop_length=HOP_LENGTH)\n\n    #MFCC algorthm works as.. STFT ->MEL filterbank(triangular) -> log -> DCT\n    return mfcc\n\n\n\n#Looping \n\n\nmel_features = []\nmfcc_features = []\nfile_names = []\n\nfor file in tqdm(os.listdir(auto_dir)):\n    if file.endswith(\".wav\"):\n\n        path = os.path.join(auto_dir, file)\n\n        \n        mel =extract_mel_spectrogram(path)\n        mfcc = extract_mfcc(path)\n\n        mel_features.append(mel)\n        mfcc_features.append(mfcc)\n        file_names.append(file)\n\nmel_features = np.array(mel_features, dtype = object)\nmfcc_features = np.array(mfcc_features, dtype = object)\n\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:19:05.079994Z","iopub.execute_input":"2026-01-31T16:19:05.080493Z","iopub.status.idle":"2026-01-31T16:22:58.434712Z","shell.execute_reply.started":"2026-01-31T16:19:05.080451Z","shell.execute_reply":"2026-01-31T16:22:58.433523Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 6075/6075 [03:40<00:00, 27.57it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport librosa\n\nx = []\ny = []\n\n#preparing 1D feature \n\nfor mel, fname in zip(mel_features, file_names):\n    orginal_fname = get_orginal_filename(fname)\n    label = filename_to_label[orginal_fname]\n\n    mel_mean = np.mean(mel,axis =1)\n    x.append(mel_mean)\n    y.append(label)\n    \n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split( x, y, test_size=0.2, random_state=42, stratify = y)\n\nfor i in range(len(y_train)):\n    y_train[i] = y_train[i]-1\n\nfor j in range(len(y_val)):\n    y_val[j] = y_val[j] - 1\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:34:14.633327Z","iopub.execute_input":"2026-01-31T16:34:14.636359Z","iopub.status.idle":"2026-01-31T16:34:19.263233Z","shell.execute_reply.started":"2026-01-31T16:34:14.636207Z","shell.execute_reply":"2026-01-31T16:34:19.262213Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\nimport xgboost as xgb\n\ndtrain =xgb.DMatrix( X_train, label = y_train)\ndval = xgb.DMatrix(X_val, label=y_val)\n\nparams = {\n    \"objective\": \"multi:softmax\",\n    \"num_class\" : 27,\n    \"eval_metric\":\"merror\",\n    \"subsample\":1,\n    \"min_child_weight\":1,\n    \"max_depth\":6,\n    \"learning_rate\":0.3,\n    \"eval_metric\" : \"mlogloss\"\n}\n\nnum_rounds = 100\n\nmodel = xgb.train(\n    params,\n    dtrain,\n    num_boost_round = num_rounds,\n    evals=[(dval, \"validation\")])\n\npreds = model.predict(dval)\naccuracy = (preds==y_val).mean()\nprint(\"validation _accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:37:22.011490Z","iopub.execute_input":"2026-01-29T15:37:22.011840Z","iopub.status.idle":"2026-01-29T15:37:26.078007Z","shell.execute_reply.started":"2026-01-29T15:37:22.011812Z","shell.execute_reply":"2026-01-29T15:37:26.077427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, Dropout)\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:54:38.769942Z","iopub.execute_input":"2026-01-31T16:54:38.770563Z","iopub.status.idle":"2026-01-31T16:54:59.487004Z","shell.execute_reply.started":"2026-01-31T16:54:38.770522Z","shell.execute_reply":"2026-01-31T16:54:59.485933Z"}},"outputs":[{"name":"stderr","text":"2026-01-31 16:54:41.313671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769878481.594540      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769878481.674815      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769878482.353276      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769878482.353343      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769878482.353347      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769878482.353350      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"Num_Classes = 27\nInput_Shape = (128, 431,3)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(\n    filters = 24,\n    kernel_size = (6,6),\n    activation = 'relu',\n    input_shape = Input_Shape\n))\n\nmodel.add(MaxPooling2D(pool_size=(4,2)))\n\nmodel.add(Conv2D(\n    filters = 48,\n    kernel_size = (5,5),\n    activation = 'relu',\n    padding = \"same\"\n))\n\nmodel.add(Conv2D(\n    filters = 48,\n    kernel_size = (5,5),\n    activation = 'relu',\n    padding = \"same\"\n))\n\nmodel.add(Conv2D(\n    filters = 60,\n    kernel_size = (4,4),\n    activation = 'relu',\n    padding = \"same\"\n))\n\nmodel.add(Conv2D(\n    filters = 72,\n    kernel_size = (4,4),\n    activation = 'relu',\n    padding = \"same\"\n))\n\nmodel.add(Conv2D(\n    filters = 80,\n    kernel_size = (3,3),\n    activation = 'relu',\n    padding = \"same\"\n))\n\nmodel.add(Conv2D(\n    filters = 80,\n    kernel_size = (3,3),\n    activation = 'relu',\n    padding = \"same\"\n))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation  = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(Num_Classes, activation = 'softmax'))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:54:59.488855Z","iopub.execute_input":"2026-01-31T16:54:59.490077Z","iopub.status.idle":"2026-01-31T16:55:00.242037Z","shell.execute_reply.started":"2026-01-31T16:54:59.490032Z","shell.execute_reply":"2026-01-31T16:55:00.240980Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n2026-01-31 16:54:59.507659: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"early_stop = EarlyStopping(\n    monitor = 'val_loss',\n    patience = 5,\n    restore_best_weights = True\n    )\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data = (X_val, y_val),\n    epochs = 50,\n    batch_size = 32,\n    callbacks = [early_stop]\n    )\n\nmodel.summary()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:17:28.065817Z","iopub.execute_input":"2026-01-31T17:17:28.066410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}