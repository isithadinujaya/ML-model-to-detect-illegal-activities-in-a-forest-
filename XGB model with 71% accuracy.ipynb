{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4213460,"sourceType":"datasetVersion","datasetId":2483929}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndata_csv = pd.read_csv('/kaggle/input/fsc22-dataset/Metadata-20220916T202011Z-001/Metadata/Metadata V1.0 FSC22.csv')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:20:46.474319Z","iopub.execute_input":"2026-01-29T14:20:46.475112Z","iopub.status.idle":"2026-01-29T14:20:48.266911Z","shell.execute_reply.started":"2026-01-29T14:20:46.475081Z","shell.execute_reply":"2026-01-29T14:20:48.265392Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_csv\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:20:48.268910Z","iopub.execute_input":"2026-01-29T14:20:48.269317Z","iopub.status.idle":"2026-01-29T14:20:48.308642Z","shell.execute_reply.started":"2026-01-29T14:20:48.269278Z","shell.execute_reply":"2026-01-29T14:20:48.307632Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                       Source File Name Dataset File Name  \\\n0                                          17548__A.wav       1_10101.wav   \n1                                           17548_B.wav       1_10102.wav   \n2                                           17548_C.wav       1_10103.wav   \n3                                           17548_D.wav       1_10104.wav   \n4                                           17548_E.wav       1_10105.wav   \n...                                                 ...               ...   \n2020                   164882__timsc__squirrel-call.wav      27_12771.wav   \n2021  162648__cognito-perceptu__park-bench-atmospher...      27_12772.wav   \n2022         122260__echobones__angry-squirrel-long.wav      27_12773.wav   \n2023  82828__noisecollector__angrysquirrel-creepingt...      27_12774.wav   \n2024  82829__noisecollector__angrysquirrel-flyingair...      27_12775.wav   \n\n      Class ID Class Name  \n0            1       Fire  \n1            1       Fire  \n2            1       Fire  \n3            1       Fire  \n4            1       Fire  \n...        ...        ...  \n2020        27   Squirrel  \n2021        27   Squirrel  \n2022        27   Squirrel  \n2023        27   Squirrel  \n2024        27   Squirrel  \n\n[2025 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source File Name</th>\n      <th>Dataset File Name</th>\n      <th>Class ID</th>\n      <th>Class Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17548__A.wav</td>\n      <td>1_10101.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17548_B.wav</td>\n      <td>1_10102.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17548_C.wav</td>\n      <td>1_10103.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17548_D.wav</td>\n      <td>1_10104.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17548_E.wav</td>\n      <td>1_10105.wav</td>\n      <td>1</td>\n      <td>Fire</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>164882__timsc__squirrel-call.wav</td>\n      <td>27_12771.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2021</th>\n      <td>162648__cognito-perceptu__park-bench-atmospher...</td>\n      <td>27_12772.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2022</th>\n      <td>122260__echobones__angry-squirrel-long.wav</td>\n      <td>27_12773.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2023</th>\n      <td>82828__noisecollector__angrysquirrel-creepingt...</td>\n      <td>27_12774.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n    <tr>\n      <th>2024</th>\n      <td>82829__noisecollector__angrysquirrel-flyingair...</td>\n      <td>27_12775.wav</td>\n      <td>27</td>\n      <td>Squirrel</td>\n    </tr>\n  </tbody>\n</table>\n<p>2025 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"We have 2025 data sets as our audio data sets.\n\nto Augment the data set and widen it we pitch 2 steps up and down in each audio file","metadata":{}},{"cell_type":"code","source":"import librosa\nimport soundfile as sf\nfrom tqdm import tqdm\nimport os\n\ninput_dir = \"/kaggle/input/fsc22-dataset/Audio Wise V1.0-20220916T202003Z-001/Audio Wise V1.0\"\n\noutput_dir = \"/kaggle/working/FSC22_augmented\"\nos.makedirs(output_dir, exist_ok = True)\n\n\nPITCH_STEPS = [2,-2]\n\nfor file in tqdm(os.listdir(input_dir)):\n    if file.endswith(\".wav\"):\n        file_path = os.path.join(input_dir, file)\n\n        y, sr = librosa.load(file_path, sr=None) #loading the audio\n\n        sf.write(os.path.join(output_dir, file),y,sr)\n\n        for step in PITCH_STEPS:\n            y_shifted = librosa.effects.pitch_shift(y,sr= sr, n_steps=step)\n            base, ext = os.path.splitext(file)\n            new_filename=f\"{base}_pitch{step}{ext}\"\n            sf.write(os.path.join(output_dir, new_filename), y_shifted, sr)\n\nprint(\"Augmentation Completed!\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T14:20:57.306195Z","iopub.execute_input":"2026-01-29T14:20:57.306716Z","iopub.status.idle":"2026-01-29T14:31:17.615190Z","shell.execute_reply.started":"2026-01-29T14:20:57.306681Z","shell.execute_reply":"2026-01-29T14:31:17.614189Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2025/2025 [10:20<00:00,  3.27it/s]","output_type":"stream"},{"name":"stdout","text":"Augmentation Completed!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"filename_to_label= {}\n\nfor i, row in data_csv.iterrows():\n    filename = row[\"Dataset File Name\"]\n    class_id = row[\"Class ID\"]\n    filename_to_label[filename] = class_id\n\ndef get_orginal_filename(filename):\n    base, ext = os.path.splitext(filename)\n    if \"_pitch\" in base:\n        base = base.split(\"_pitch\")[0]\n    return base + ext\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:05:13.841335Z","iopub.execute_input":"2026-01-29T15:05:13.842261Z","iopub.status.idle":"2026-01-29T15:05:13.939403Z","shell.execute_reply.started":"2026-01-29T15:05:13.842225Z","shell.execute_reply":"2026-01-29T15:05:13.938243Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Since we have augmented the data set now we are trying to do feature extraction.\n\nfor ausio signal processing, we use MFCC and melspectrogram methods using librosa library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nauto_dir = \"/kaggle/working/FSC22_augmented\"\n\n#Feature Extraction Parameters\n\nSR = 22050 #sampling rate\nN_FFT = 2048  #number of samples per FFT window\nHOP_LENGTH = 512 #\nN_MELS = 128 #number of mel frequency bands. 128 is ide\nN_MFCC = 13 #number of MFCC coefficients\n\ndef extract_mel_spectrogram(file_path):\n    y, sr = librosa.load(file_path, sr=SR) # Y is the 1D waveform array\n    mel_spec = librosa.feature.melspectrogram( y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n    mel_specs_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n    return mel_specs_db\n\ndef extract_mfcc(file_path):\n    y, sr = librosa.load(file_path, sr=SR)\n    mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=N_MFCC,n_fft=N_FFT,hop_length=HOP_LENGTH)\n\n    #MFCC algorthm works as.. STFT ->MEL filterbank(triangular) -> log -> DCT\n    return mfcc\n\n\n\n#Looping \n\n\nmel_features = []\nmfcc_features = []\nfile_names = []\n\nfor file in tqdm(os.listdir(auto_dir)):\n    if file.endswith(\".wav\"):\n\n        path = os.path.join(auto_dir, file)\n\n        \n        mel =extract_mel_spectrogram(path)\n        mfcc = extract_mfcc(path)\n\n        mel_features.append(mel)\n        mfcc_features.append(mfcc)\n        file_names.append(file)\n\nmel_features = np.array(mel_features, dtype = object)\nmfcc_features = np.array(mfcc_features, dtype = object)\n\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:17:14.697110Z","iopub.execute_input":"2026-01-29T15:17:14.697857Z","iopub.status.idle":"2026-01-29T15:21:14.934958Z","shell.execute_reply.started":"2026-01-29T15:17:14.697823Z","shell.execute_reply":"2026-01-29T15:21:14.933909Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 6075/6075 [03:48<00:00, 26.62it/s]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import os\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport librosa\n\nx = []\ny = []\n\n#preparing 1D feature \n\nfor mfcc, fname in zip(mfcc_features, file_names):\n    orginal_fname = get_orginal_filename(fname)\n    label = filename_to_label[orginal_fname]\n\n    mfcc_mean = np.mean(mfcc,axis =1)\n    x.append(mfcc_mean)\n    y.append(label)\n    \n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:34:13.894598Z","iopub.execute_input":"2026-01-29T15:34:13.895125Z","iopub.status.idle":"2026-01-29T15:34:14.376721Z","shell.execute_reply.started":"2026-01-29T15:34:13.895090Z","shell.execute_reply":"2026-01-29T15:34:14.375296Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split( x, y, test_size=0.2, random_state=42, stratify = y)\n\nfor i in range(len(y_train)):\n    y_train[i] = y_train[i]-1\n\nfor j in range(len(y_val)):\n    y_val[j] = y_val[j] - 1\n\n\nimport xgboost as xgb\n\ndtrain =xgb.DMatrix( X_train, label = y_train)\ndval = xgb.DMatrix(X_val, label=y_val)\n\nparams = {\n    \"objective\": \"multi:softmax\",\n    \"num_class\" : 27,\n    \"eval_metric\":\"merror\",\n    \"subsample\":1,\n    \"min_child_weight\":1,\n    \"max_depth\":6,\n    \"learning_rate\":0.3,\n    \"eval_metric\" : \"mlogloss\"\n}\n\nnum_rounds = 100\n\nmodel = xgb.train(\n    params,\n    dtrain,\n    num_boost_round = num_rounds,\n    evals=[(dval, \"validation\")])\n\npreds = model.predict(dval)\naccuracy = (preds==y_val).mean()\nprint(\"validation _accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T15:37:22.011490Z","iopub.execute_input":"2026-01-29T15:37:22.011840Z","iopub.status.idle":"2026-01-29T15:37:26.078007Z","shell.execute_reply.started":"2026-01-29T15:37:22.011812Z","shell.execute_reply":"2026-01-29T15:37:26.077427Z"}},"outputs":[{"name":"stdout","text":"[0]\tvalidation-mlogloss:2.60659\n[1]\tvalidation-mlogloss:2.34088\n[2]\tvalidation-mlogloss:2.16948\n[3]\tvalidation-mlogloss:2.03387\n[4]\tvalidation-mlogloss:1.93115\n[5]\tvalidation-mlogloss:1.83982\n[6]\tvalidation-mlogloss:1.76980\n[7]\tvalidation-mlogloss:1.70440\n[8]\tvalidation-mlogloss:1.65077\n[9]\tvalidation-mlogloss:1.60982\n[10]\tvalidation-mlogloss:1.57009\n[11]\tvalidation-mlogloss:1.53826\n[12]\tvalidation-mlogloss:1.50220\n[13]\tvalidation-mlogloss:1.47120\n[14]\tvalidation-mlogloss:1.44174\n[15]\tvalidation-mlogloss:1.41127\n[16]\tvalidation-mlogloss:1.38332\n[17]\tvalidation-mlogloss:1.36354\n[18]\tvalidation-mlogloss:1.34421\n[19]\tvalidation-mlogloss:1.32537\n[20]\tvalidation-mlogloss:1.30565\n[21]\tvalidation-mlogloss:1.28389\n[22]\tvalidation-mlogloss:1.27097\n[23]\tvalidation-mlogloss:1.25776\n[24]\tvalidation-mlogloss:1.24447\n[25]\tvalidation-mlogloss:1.23148\n[26]\tvalidation-mlogloss:1.21740\n[27]\tvalidation-mlogloss:1.20877\n[28]\tvalidation-mlogloss:1.20194\n[29]\tvalidation-mlogloss:1.18993\n[30]\tvalidation-mlogloss:1.17844\n[31]\tvalidation-mlogloss:1.16963\n[32]\tvalidation-mlogloss:1.16321\n[33]\tvalidation-mlogloss:1.15473\n[34]\tvalidation-mlogloss:1.14506\n[35]\tvalidation-mlogloss:1.13664\n[36]\tvalidation-mlogloss:1.12870\n[37]\tvalidation-mlogloss:1.11988\n[38]\tvalidation-mlogloss:1.11404\n[39]\tvalidation-mlogloss:1.10633\n[40]\tvalidation-mlogloss:1.10202\n[41]\tvalidation-mlogloss:1.09544\n[42]\tvalidation-mlogloss:1.08999\n[43]\tvalidation-mlogloss:1.08599\n[44]\tvalidation-mlogloss:1.08440\n[45]\tvalidation-mlogloss:1.07959\n[46]\tvalidation-mlogloss:1.07623\n[47]\tvalidation-mlogloss:1.07122\n[48]\tvalidation-mlogloss:1.06936\n[49]\tvalidation-mlogloss:1.06604\n[50]\tvalidation-mlogloss:1.06203\n[51]\tvalidation-mlogloss:1.05892\n[52]\tvalidation-mlogloss:1.05665\n[53]\tvalidation-mlogloss:1.05311\n[54]\tvalidation-mlogloss:1.04736\n[55]\tvalidation-mlogloss:1.04281\n[56]\tvalidation-mlogloss:1.04155\n[57]\tvalidation-mlogloss:1.04110\n[58]\tvalidation-mlogloss:1.04036\n[59]\tvalidation-mlogloss:1.03794\n[60]\tvalidation-mlogloss:1.03510\n[61]\tvalidation-mlogloss:1.03254\n[62]\tvalidation-mlogloss:1.03211\n[63]\tvalidation-mlogloss:1.03121\n[64]\tvalidation-mlogloss:1.02959\n[65]\tvalidation-mlogloss:1.02790\n[66]\tvalidation-mlogloss:1.02672\n[67]\tvalidation-mlogloss:1.02484\n[68]\tvalidation-mlogloss:1.02189\n[69]\tvalidation-mlogloss:1.01996\n[70]\tvalidation-mlogloss:1.01954\n[71]\tvalidation-mlogloss:1.01828\n[72]\tvalidation-mlogloss:1.01745\n[73]\tvalidation-mlogloss:1.01699\n[74]\tvalidation-mlogloss:1.01757\n[75]\tvalidation-mlogloss:1.01600\n[76]\tvalidation-mlogloss:1.01363\n[77]\tvalidation-mlogloss:1.01429\n[78]\tvalidation-mlogloss:1.01416\n[79]\tvalidation-mlogloss:1.01342\n[80]\tvalidation-mlogloss:1.01340\n[81]\tvalidation-mlogloss:1.01318\n[82]\tvalidation-mlogloss:1.01211\n[83]\tvalidation-mlogloss:1.01228\n[84]\tvalidation-mlogloss:1.01098\n[85]\tvalidation-mlogloss:1.01190\n[86]\tvalidation-mlogloss:1.01030\n[87]\tvalidation-mlogloss:1.01065\n[88]\tvalidation-mlogloss:1.00958\n[89]\tvalidation-mlogloss:1.00996\n[90]\tvalidation-mlogloss:1.00956\n[91]\tvalidation-mlogloss:1.00983\n[92]\tvalidation-mlogloss:1.00869\n[93]\tvalidation-mlogloss:1.00821\n[94]\tvalidation-mlogloss:1.00873\n[95]\tvalidation-mlogloss:1.00855\n[96]\tvalidation-mlogloss:1.00821\n[97]\tvalidation-mlogloss:1.00758\n[98]\tvalidation-mlogloss:1.00661\n[99]\tvalidation-mlogloss:1.00687\nvalidation _accuracy: 0.7119341563786008\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}